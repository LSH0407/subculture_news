#!/usr/bin/env python3
"""
X(íŠ¸ìœ„í„°) RSS í”¼ë“œë¥¼ í†µí•œ ê²Œì„ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë˜í•‘
Nitter ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ API í‚¤ ì—†ì´ íŠ¸ìœ— ìˆ˜ì§‘
"""
import sys
import io
import json
import re
from datetime import datetime
import feedparser
from typing import List, Dict, Tuple

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Nitter ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ (fallback ì§€ì›)
NITTER_INSTANCES = [
    "nitter.poast.org",
    "nitter.privacydev.net",
    "nitter.net",
]

# ê³µì‹ ê³„ì •
ACCOUNTS = {
    "star_rail": "honkaisr_kr",  # ë¶•ê´´: ìŠ¤íƒ€ë ˆì¼ í•œêµ­ ê³µì‹
    "zzz": "ZZZ_KO",  # ì  ë ˆìŠ¤ ì¡´ ì œë¡œ í•œêµ­ ê³µì‹
}

# í‚¤ì›Œë“œ ê°ì§€
KEYWORDS = {
    "star_rail": ["ì›Œí”„", "ì´ë²¤íŠ¸ ì›Œí”„", "í”½ì—…", "í™•ë¥  UP", "ì¶œì‹œ"],
    "zzz": ["ì±„ë„", "ê¸°ê°„ í•œì •", "í”½ì—…", "í™•ë¥  UP", "ì¶œì‹œ"],
}

def fetch_tweets(account: str, instance: str) -> List[Dict]:
    """RSS í”¼ë“œì—ì„œ íŠ¸ìœ— ê°€ì ¸ì˜¤ê¸°"""
    feed_url = f"https://{instance}/{account}/rss"
    print(f"Fetching: {feed_url}")
    
    try:
        feed = feedparser.parse(feed_url)
        if not feed.entries:
            print(f"  âš ï¸  No entries found")
            return []
        
        print(f"  âœ… Found {len(feed.entries)} tweets")
        
        tweets = []
        for entry in feed.entries:
            tweets.append({
                "title": entry.get("title", ""),
                "description": entry.get("description", ""),
                "link": entry.get("link", ""),
                "published": entry.get("published", ""),
                "published_parsed": entry.get("published_parsed"),
            })
        
        return tweets
    
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []

def extract_date_from_tweet(text: str) -> Tuple[str, str]:
    """íŠ¸ìœ—ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ"""
    # íŒ¨í„´ 1: MM/DD ~ MM/DD
    m = re.search(r"(\d{1,2})/(\d{1,2})\s*[~\-â€“â€”]\s*(\d{1,2})/(\d{1,2})", text)
    if m:
        year = datetime.now().year
        start = f"{year}-{int(m.group(1)):02d}-{int(m.group(2)):02d}"
        end = f"{year}-{int(m.group(3)):02d}-{int(m.group(4)):02d}"
        return start, end
    
    # íŒ¨í„´ 2: YYYY/MM/DD ~ YYYY/MM/DD
    m = re.search(r"(\d{4})/(\d{1,2})/(\d{1,2})\s*[~\-â€“â€”]\s*(\d{4})/(\d{1,2})/(\d{1,2})", text)
    if m:
        start = f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
        end = f"{m.group(4)}-{int(m.group(5)):02d}-{int(m.group(6)):02d}"
        return start, end
    
    # íŒ¨í„´ 3: Xì›” Xì¼ ~ Xì›” Xì¼
    m = re.search(r"(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼\s*[~\-â€“â€”]\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", text)
    if m:
        year = datetime.now().year
        start = f"{year}-{int(m.group(1)):02d}-{int(m.group(2)):02d}"
        end = f"{year}-{int(m.group(3)):02d}-{int(m.group(4)):02d}"
        return start, end
    
    return "", ""

def parse_tweets(game_id: str, tweets: List[Dict]) -> List[Dict]:
    """íŠ¸ìœ—ì—ì„œ ì—…ë°ì´íŠ¸ ì •ë³´ íŒŒì‹±"""
    updates = []
    keywords = KEYWORDS.get(game_id, [])
    
    for tweet in tweets:
        title = tweet["title"]
        desc = tweet["description"]
        full_text = f"{title}\n{desc}"
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        if not any(kw in full_text for kw in keywords):
            continue
        
        print(f"\nğŸ” í‚¤ì›Œë“œ ê°ì§€: {title[:60]}")
        
        # ë‚ ì§œ ì¶”ì¶œ
        start_date, end_date = extract_date_from_tweet(full_text)
        
        if not start_date:
            # ê²Œì‹œ ë‚ ì§œ ì‚¬ìš©
            if tweet["published_parsed"]:
                pub_time = tweet["published_parsed"]
                start_date = f"{pub_time.tm_year}-{pub_time.tm_mon:02d}-{pub_time.tm_mday:02d}"
                print(f"  â„¹ï¸  ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨, ê²Œì‹œ ë‚ ì§œ ì‚¬ìš©: {start_date}")
        
        if start_date:
            update = {
                "game_id": game_id,
                "version": "",  # ë²„ì „ì€ ë³„ë„ íŒŒì‹± í•„ìš”
                "update_date": start_date,
                "description": title,
                "url": tweet["link"],
            }
            
            if end_date:
                update["end_date"] = end_date
            
            updates.append(update)
            print(f"  âœ… ì¶”ê°€: {start_date} ~ {end_date or 'N/A'}")
    
    return updates

def main():
    print("=" * 60)
    print("X(íŠ¸ìœ„í„°) RSS í”¼ë“œ ìŠ¤í¬ë˜í¼")
    print("=" * 60)
    
    all_updates = []
    
    # ê° ê²Œì„ë³„ë¡œ ìŠ¤í¬ë˜í•‘
    for game_id, account in ACCOUNTS.items():
        print(f"\n### {game_id.upper()} (@{account}) ###")
        
        tweets = None
        # Nitter ì¸ìŠ¤í„´ìŠ¤ fallback
        for instance in NITTER_INSTANCES:
            tweets = fetch_tweets(account, instance)
            if tweets:
                break
        
        if not tweets:
            print(f"  âš ï¸  ëª¨ë“  Nitter ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤íŒ¨")
            continue
        
        # íŠ¸ìœ— íŒŒì‹±
        updates = parse_tweets(game_id, tweets)
        all_updates.extend(updates)
        print(f"  ğŸ“Š ì´ {len(updates)}ê°œ ì—…ë°ì´íŠ¸ ê°ì§€")
    
    # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
    print("\n" + "=" * 60)
    print("ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©")
    print("=" * 60)
    
    try:
        with open('data/updates.json', 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
    except FileNotFoundError:
        existing_data = []
    
    print(f"ê¸°ì¡´ ì—…ë°ì´íŠ¸ ìˆ˜: {len(existing_data)}")
    print(f"ìƒˆë¡œìš´ ì—…ë°ì´íŠ¸ ìˆ˜: {len(all_updates)}")
    
    # ì¤‘ë³µ ì œê±°
    def key(u):
        return f"{u.get('game_id')}|{u.get('update_date')}|{u.get('description','')[:40]}"
    
    existing_keys = {key(u) for u in existing_data}
    added = 0
    
    for update in all_updates:
        if key(update) not in existing_keys:
            existing_data.append(update)
            added += 1
            print(f"  âœ… ì¶”ê°€: {update['game_id']} - {update['description'][:50]}")
    
    if added > 0:
        with open('data/updates.json', 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… {added}ê°œ ìƒˆ ì—…ë°ì´íŠ¸ ì¶”ê°€ ì™„ë£Œ!")
    else:
        print(f"\nâœ… ìƒˆë¡œìš´ ì—…ë°ì´íŠ¸ ì—†ìŒ")
    
    print(f"ìµœì¢… ì—…ë°ì´íŠ¸ ìˆ˜: {len(existing_data)}")

if __name__ == "__main__":
    main()

